{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66adc147",
   "metadata": {},
   "source": [
    "# 1- Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6796ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import statsmodels.stats.proportion as prop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88669894",
   "metadata": {},
   "source": [
    "# 2 - Conexao com o banco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6baa6030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # conexao com o banco e query\n",
    "    conn = sqlite3.connect('/Users/User/Documents/repos/case_workana/dastabase.sqlite')\n",
    "    query = '''\n",
    "\n",
    "    with tb_accepted_bids as (\n",
    "    -- cte com os bids aceitos e as datas para filtro (as datas vem da tabela de bids)\n",
    "        select \n",
    "            a.bid_id,\n",
    "            b.project_id, \n",
    "            1 as flg_accepted_bid,\n",
    "            b.created_date\n",
    "        from \n",
    "            accepted_bids as a\n",
    "        left join \n",
    "            bids as b on a.bid_id = b.id\n",
    "        where \n",
    "            1=1\n",
    "            and b.created_date between '03-07-2025' and '21-07-2025' \n",
    "            and a.status = 'active'\n",
    "            and b.id is not null \n",
    "    )\n",
    "\n",
    "    -- cte final que traz os bids aceitos para os project_id da base do teste\n",
    "    select\n",
    "        a.id,\n",
    "        a.project_id,\n",
    "        a.name,\n",
    "        a.segment,\n",
    "        a.created as data_teste,\n",
    "        b.*\n",
    "    from \n",
    "        abtests as a\n",
    "    left join \n",
    "        tb_accepted_bids as b on a.project_id = b.project_id  \n",
    "\n",
    "\n",
    "    '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef8b7cf",
   "metadata": {},
   "source": [
    "# 3 - Cria√ßao de df e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d740ce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste of difference in proportions: evalbidsNewOrder vs default\n",
      "Z = 1.7130, p = 0.0434\n",
      "Significative: YES\n",
      "IC diff between groups -0.00349914172178966, 0.0518328641974533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_9188\\1289548011.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_teste['bid_aceito'] = df_teste['bid_id'].notna()\n"
     ]
    }
   ],
   "source": [
    "#%% \n",
    "\n",
    "# criacao do df\n",
    "df = pd.read_sql(query, con=conn)\n",
    "df_teste = df[['segment', 'bid_id']]\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "## aplica√ßao do teste z de proporcoes \n",
    "## amostras grandes o suficiente\n",
    "## nao √© necessario testar normalidade porque o teste ja se aproxima da distribui√ßao normal\n",
    "## apenas dois grupos (se fosse mais seria chi quadrado)\n",
    "\n",
    "\n",
    "\n",
    "# Hipotese nula: a propor√ßao de sucesso do grupo de teste √© menor ou igual a propor√ßao do grupo controle (status quo)\n",
    "# Hipotese alternativa:  a propor√ßao de sucesso do grupo de teste √© maior do que a propor√ßao do grupo controle\n",
    "\n",
    "# Hnull : P1 <= P2\n",
    "# Halt : P1 > P2 \n",
    "\n",
    "# Onde P1 √© evalbidsNewOrder e P2 √© default\n",
    "\n",
    "\n",
    "#############################################################################################################\n",
    "\n",
    "df_teste['bid_aceito'] = df_teste['bid_id'].notna()\n",
    "\n",
    "# agrupamento por base teste e controle\n",
    "contagens = df_teste.groupby('segment')['bid_aceito'].agg(['count', 'sum']).reset_index()\n",
    "contagens.columns = ['segment', 'total', 'sucessos']\n",
    "\n",
    "segmentos_para_teste = contagens.head(2) \n",
    "\n",
    "# criacao de listas com os dados sucesso e de cada grupo para o teste\n",
    "\n",
    "p1 = contagens.loc[contagens['segment'] == 'evalbidsNewOrder', 'sucessos'].iloc[0]\n",
    "p2 = contagens.loc[contagens['segment'] == 'default', 'sucessos'].iloc[0]\n",
    "\n",
    "p1_total_amostra = contagens.loc[contagens['segment'] == 'evalbidsNewOrder', 'total'].iloc[0]\n",
    "p2_total_amostra = contagens.loc[contagens['segment'] == 'default', 'total'].iloc[0]\n",
    "#%%\n",
    "\n",
    "sucessos = [p1,p2]\n",
    "totais = [p1_total_amostra, p2_total_amostra]\n",
    "\n",
    "\n",
    "# aplicacao do teste\n",
    "stat, pvalor = prop.proportions_ztest(count=sucessos, nobs=totais, alternative='larger' )    \n",
    "\n",
    "\n",
    "# calculo intervalo de confian√ßa\n",
    "\n",
    "# calculo de propor√ßoes\n",
    "p1_hat = p1 / p1_total_amostra\n",
    "p2_hat = p2 / p2_total_amostra\n",
    "diff = p1_hat - p2_hat\n",
    "\n",
    "# tamanho da amostra\n",
    "\n",
    "# z score (para 95% de confian√ßa √© 1.96)\n",
    "z_score = 1.96\n",
    "\n",
    "# calculo da margem de erro\n",
    "margem_de_erro_p1 = z_score * np.sqrt(p1_hat*(1-p1_hat)/p1_total_amostra)\n",
    "margem_de_erro_p2 = z_score * np.sqrt(p2_hat*(1-p2_hat)/p2_total_amostra)\n",
    "\n",
    "margem_de_erro_diff = z_score * np.sqrt((p1_hat * (1 - p1_hat) / p1_total_amostra) + (p2_hat * (1 - p2_hat) / p2_total_amostra))\n",
    "\n",
    "# calculo IC\n",
    "lower_bound_p1 = p1_hat - margem_de_erro_p1 \n",
    "upper_bound_p1 = p1_hat + margem_de_erro_p1\n",
    "\n",
    "lower_bound_p2 = p2_hat - margem_de_erro_p2\n",
    "upper_bound_p2 = p2_hat + margem_de_erro_p2\n",
    "\n",
    "lower_bound_diff = diff - margem_de_erro_diff\n",
    "upper_bound_diff = diff + margem_de_erro_diff\n",
    "\n",
    "\n",
    "print(f\"Teste of difference in proportions: {df['segment'].unique()[0]} vs {df['segment'].unique()[1]}\")\n",
    "print(f\"Z = {stat:.4f}, p = {pvalor:.4f}\")\n",
    "print(f\"Significative: {'YES' if pvalor < 0.05 else 'N√ÉO'}\")\n",
    "print(f'IC diff between groups {lower_bound_diff}, {upper_bound_diff}')\n",
    "#print(f'IC grupo teste {lower_bound_p1}, {upper_bound_p1}')\n",
    "#print(f'IC grupo controle {lower_bound_p2}, {upper_bound_p2}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c571137",
   "metadata": {},
   "source": [
    "## 4 - Calculo de novo tamanho de amostra para teste posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74fab71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77892477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14580265095729014\n",
      "0.16996951219512196\n",
      "0.02416686123783182\n",
      "0.15788608157620604\n",
      "Sample size needed per group: 3467.2412971367894\n",
      "Total sample sixe 6934\n"
     ]
    }
   ],
   "source": [
    "significance_95_percent = 1.96\n",
    "statistical_power_80_percent = 0.8 # default do mercado\n",
    "mde = 0\n",
    "baseline_conversion_rate = p2 / p2_total_amostra\n",
    "test_conversion_rate = p1 / p1_total_amostra\n",
    "mde = test_conversion_rate - baseline_conversion_rate\n",
    "pooled_cr = (test_conversion_rate + baseline_conversion_rate) / 2\n",
    "\n",
    "numerator = (significance_95_percent * np.sqrt(2 * pooled_cr * (1 - pooled_cr)) + \n",
    "             statistical_power_80_percent * np.sqrt(test_conversion_rate*(1-test_conversion_rate) + baseline_conversion_rate*(1-baseline_conversion_rate)))**2\n",
    "denominator = mde**2\n",
    "\n",
    "sample_size_per_group = numerator / denominator\n",
    "\n",
    "\n",
    "\n",
    "print(baseline_conversion_rate)\n",
    "print(test_conversion_rate)\n",
    "print(mde)\n",
    "print(pooled_cr)\n",
    "print(f\"Sample size needed per group: {sample_size_per_group}\") \n",
    "print(f'Total sample sixe {(2 * sample_size_per_group).astype(int)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a520487",
   "metadata": {},
   "source": [
    "### BACKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4caddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = ''' with tb_accepted_bids as (\n",
    "    -- cte com os bids aceitos e as datas para filtro (as datas vem da tabela de bids)\n",
    "        select \n",
    "            a.bid_id,\n",
    "            b.project_id, \n",
    "            1 as flg_accepted_bid,\n",
    "            b.created_date,\n",
    "\t\t\tcase when b.usd_amount is null then 0 else b.usd_amount end as usd_amount\n",
    "        from \n",
    "            accepted_bids as a\n",
    "        left join \n",
    "            bids as b on a.bid_id = b.id\n",
    "        where \n",
    "            1=1\n",
    "            and b.created_date between '03-07-2025' and '21-07-2025' \n",
    "            and a.status = 'active'\n",
    "            and b.id is not null \n",
    "    )\n",
    "\n",
    "    -- cte final que traz os bids aceitos para os project_id da base do teste\n",
    "    select\n",
    "        a.id,\n",
    "        a.project_id,\n",
    "        a.name,\n",
    "        a.segment,\n",
    "        a.created as data_teste,\n",
    "        b.*\n",
    "    from \n",
    "        abtests as a\n",
    "    left join \n",
    "        tb_accepted_bids as b on a.project_id = b.project_id  \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbe02a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste de Levene: p = 0.9272. Assumindo vari√¢ncias iguais: True\n",
      "\n",
      "======================================================================\n",
      "Resultado do Teste t de Diferen√ßa de M√©dias (Unilateral: Œº1 > Œº2)\n",
      "======================================================================\n",
      "Grupo Teste ('evalbidsNewOrder') M√©dia: 140.2500, N: 68\n",
      "Grupo Controle ('default') M√©dia: 148.2264, N: 53\n",
      "Diferen√ßa de M√©dias (Teste - Controle): -7.9764\n",
      "Estat√≠stica T = -0.1314, p-valor = 0.5522\n",
      "Significativo (p < 0.05, Unilateral): N√ÉO\n",
      "IC 95% para a Diferen√ßa de M√©dias: [-128.1927, 112.2399]\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# %% \n",
    "\n",
    "# criacao do df (mantido)\n",
    "df = pd.read_sql(query2, con=conn)\n",
    "# O dataframe de teste conter√° a coluna 'usd_amount' (o valor) e 'segment' (o grupo)\n",
    "df_teste = df[['segment', 'usd_amount']].copy()\n",
    "\n",
    "# ==============================================================================\n",
    "# üí° CORRE√á√ÉO: Converter a coluna 'usd_amount' para num√©rica\n",
    "# O par√¢metro 'coerce' transforma valores n√£o num√©ricos (como strings vazias ou erros de leitura) em NaN.\n",
    "# ==============================================================================\n",
    "df_teste['usd_amount'] = pd.to_numeric(df_teste['usd_amount'], errors='coerce')\n",
    "\n",
    "\n",
    "##############################################################################################################\n",
    "\n",
    "## aplica√ßao do teste t de diferen√ßa de m√©dias para amostras independentes\n",
    "## Assumimos que a coluna 'usd_amount' representa a vari√°vel num√©rica de interesse.\n",
    "## Vamos testar a diferen√ßa entre as m√©dias dos valores de usd_amount para os dois segmentos.\n",
    "\n",
    "# Hip√≥tese nula (H0): A m√©dia do grupo de teste √© menor ou igual √† m√©dia do grupo controle (Œº1 <= Œº2)\n",
    "# Hip√≥tese alternativa (Ha): A m√©dia do grupo de teste √© maior do que a m√©dia do grupo controle (Œº1 > Œº2)\n",
    "# Onde Œº1 √© 'evalbidsNewOrder' e Œº2 √© 'default'\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# 1. Separar os dados em dois grupos\n",
    "# O .dropna() aqui √© crucial, pois a convers√£o 'coerce' pode ter criado NaN's\n",
    "grupo_teste = df_teste[df_teste['segment'] == 'evalbidsNewOrder']['usd_amount'].dropna()\n",
    "grupo_controle = df_teste[df_teste['segment'] == 'default']['usd_amount'].dropna()\n",
    "\n",
    "# 2. Verificar a premissa de igualdade de vari√¢ncias (teste de Levene)\n",
    "# √â necess√°rio garantir que haja dados suficientes em AMBOS os grupos para o teste de Levene\n",
    "if len(grupo_teste) < 2 or len(grupo_controle) < 2:\n",
    "    print(\"\\nERRO: Pelo menos um dos grupos tem menos de 2 observa√ß√µes ap√≥s remover NA's. N√£o √© poss√≠vel rodar o Teste t.\")\n",
    "else:\n",
    "    levene_test = stats.levene(grupo_teste, grupo_controle)\n",
    "    equal_variances = levene_test.pvalue > 0.05\n",
    "\n",
    "    print(f\"Teste de Levene: p = {levene_test.pvalue:.4f}. Assumindo vari√¢ncias iguais: {equal_variances}\")\n",
    "\n",
    "    # 3. Aplica√ß√£o do teste t (unilateral 'greater')\n",
    "    # 'greater' testa se a m√©dia do primeiro array (grupo_teste) √© maior que a m√©dia do segundo (grupo_controle)\n",
    "    stat, pvalor = stats.ttest_ind(\n",
    "        a=grupo_teste, \n",
    "        b=grupo_controle, \n",
    "        equal_var=equal_variances, \n",
    "        alternative='greater'\n",
    "    )    \n",
    "\n",
    "    # 4. C√°lculo do Intervalo de Confian√ßa para a Diferen√ßa de M√©dias\n",
    "    # M√©dia, desvio padr√£o e tamanho da amostra\n",
    "    mean1, std1, n1 = grupo_teste.mean(), grupo_teste.std(ddof=1), len(grupo_teste)\n",
    "    mean2, std2, n2 = grupo_controle.mean(), grupo_controle.std(ddof=1), len(grupo_controle)\n",
    "    diff_means = mean1 - mean2\n",
    "    confidence_level = 0.95 \n",
    "\n",
    "    # C√°lculo dos graus de liberdade e erro padr√£o conforme a suposi√ß√£o de vari√¢ncias (Welch/Student)\n",
    "    if equal_variances:\n",
    "        # F√≥rmula de Student\n",
    "        pooled_std = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))\n",
    "        se_diff_ic = pooled_std * np.sqrt(1/n1 + 1/n2)\n",
    "        df_ic = n1 + n2 - 2\n",
    "    else:\n",
    "        # F√≥rmula de Welch (Satterthwaite)\n",
    "        se_diff = np.sqrt((std1**2 / n1) + (std2**2 / n2))\n",
    "        se_diff_ic = se_diff\n",
    "        # Para evitar problemas de arredondamento em casos de 0 no denominador ou n < 2, \n",
    "        # √© recomendado usar uma f√≥rmula mais robusta ou o df retornado por ttest_ind se dispon√≠vel (Scipy > 1.11)\n",
    "        # Manteremos a estimativa de Satterthwaite, mas com a checagem inicial de n.\n",
    "        df_ic = (se_diff**4) / ( (std1**2 / n1)**2 / (n1 - 1) + (std2**2 / n2)**2 / (n2 - 1) )\n",
    "        \n",
    "    # T-score para 95% (bilateral)\n",
    "    t_score = stats.t.ppf(1 - (1 - confidence_level)/2, df=df_ic)\n",
    "\n",
    "    # Margem de erro e IC\n",
    "    margem_de_erro_diff = t_score * se_diff_ic\n",
    "    lower_bound_diff = diff_means - margem_de_erro_diff\n",
    "    upper_bound_diff = diff_means + margem_de_erro_diff\n",
    "\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Resultado do Teste t de Diferen√ßa de M√©dias (Unilateral: Œº1 > Œº2)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Grupo Teste ('evalbidsNewOrder') M√©dia: {mean1:.4f}, N: {n1}\")\n",
    "    print(f\"Grupo Controle ('default') M√©dia: {mean2:.4f}, N: {n2}\")\n",
    "    print(f\"Diferen√ßa de M√©dias (Teste - Controle): {diff_means:.4f}\")\n",
    "    print(f\"Estat√≠stica T = {stat:.4f}, p-valor = {pvalor:.4f}\")\n",
    "    print(f\"Significativo (p < 0.05, Unilateral): {'SIM' if pvalor < 0.05 else 'N√ÉO'}\")\n",
    "    print(f\"IC 95% para a Diferen√ßa de M√©dias: [{lower_bound_diff:.4f}, {upper_bound_diff:.4f}]\")\n",
    "    print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
